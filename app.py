import os
import pandas as pd
from flask import Flask, render_template, request, jsonify
import joblib # Modelleri okumak iÃ§in 
import numpy as np 


app = Flask(__name__)

# ==========================================
# 1. HELPER FUNCTIONS (YARDIMCI FONKSÄ°YONLAR)
# ==========================================

def get_data_path(filename):
    """
    Proje dizin yapÄ±sÄ±na gÃ¶re dinamik dosya yolu oluÅŸturur.
    
    AmaÃ§: Ä°ÅŸletim sistemi fark etmeksizin (Windows/Mac/Linux) 
    'data/processed' klasÃ¶rÃ¼ altÄ±ndaki dosyalara hatasÄ±z eriÅŸim saÄŸlamak.
    """
    base_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.join(base_dir, 'data', 'processed', filename)


# ==========================================
# 2. DATA MODULES (VERÄ° MODÃœLLERÄ°)
# ==========================================

def get_rfm_data():
    """
    RFM Analizi verilerini okur ve Dashboard KPI'larÄ± iÃ§in hazÄ±rlar.
    Kaynak: data/processed/customers_rfm.csv
    """
    file_path = get_data_path('customers_rfm.csv')
    
    try:
        # Veri okuma
        df = pd.read_csv(file_path)
        
        # SÃ¼tun isim standardizasyonu (Case-insensitive iÅŸlem iÃ§in)
        df.columns = df.columns.str.lower()
        
        # --- KPI HesaplamalarÄ± ---
        total_customers = len(df)
        
        # Ciro Hesaplama (Monetary)
        if 'monetary' in df.columns:
            total_revenue = df['monetary'].sum()
            revenue_formatted = f"{total_revenue:,.0f} â‚º"
        else:
            revenue_formatted = "Veri Yok"

        # Lider Segment (En yÃ¼ksek frekansa sahip grup)
        leading_segment = "Belirsiz"
        if 'segment' in df.columns:
            leading_segment = df['segment'].value_counts().idxmax()
        
        # --- GÃ¶rselleÅŸtirme HazÄ±rlÄ±ÄŸÄ± (Frontend FormatÄ±) ---
        
        # 1. Tablo Verisi: Ciroya gÃ¶re top 100 mÃ¼ÅŸteri
        table_data = []
        if 'monetary' in df.columns:
            table_data = df.sort_values(by='monetary', ascending=False).head(100).to_dict('records')

        # 2. Pasta Grafik Verisi: Segment daÄŸÄ±lÄ±mÄ±
        chart_labels = []
        chart_values = []
        if 'segment' in df.columns:
            segment_counts = df['segment'].value_counts()
            chart_labels = [label.replace('_', ' ').title() for label in segment_counts.index.tolist()]
            chart_values = segment_counts.values.tolist()

        return {
            "sayi": total_customers,
            "skor": revenue_formatted,
            "isim": leading_segment,
            "grafik_etiketleri": chart_labels,
            "grafik_verileri": chart_values,
            "tablo_verisi": table_data
        }

    except FileNotFoundError:
        print(f"HATA: 'customers_rfm.csv' dosyasÄ± belirtilen dizinde bulunamadÄ±.")
        return None
    except Exception as e:
        print(f"KRÄ°TÄ°K HATA (RFM ModÃ¼lÃ¼): {e}")
        return None


def get_kmeans_data():
    """
    K-Means verisini hazÄ±rlar ama grafiÄŸi bozan AYKIRI DEÄERLERÄ° (Outliers) temizler.
    """
    file_path = get_data_path('rfm_clustered.csv')
    
    try:
        df = pd.read_csv(file_path)
        df.columns = df.columns.str.lower()
        
        series_data = []
        cluster_col = 'cluster' # veya 'segment'
        
        # --- OUTLIER TEMÄ°ZLÄ°ÄÄ° (GRAFÄ°ÄÄ° FERAHLATMAK Ä°Ã‡Ä°N) ---
        # HarcamanÄ±n %95'inden fazlasÄ±nÄ± yapanlarÄ± grafiÄŸe almÄ±yoruz.
        # Bu, grafiÄŸin "zoom" yapmasÄ±nÄ± ve kÃ¼melerin ayrÄ±ÅŸmasÄ±nÄ± saÄŸlar.
        esik_deger = df['monetary'].quantile(0.95)
        df_filtered = df[df['monetary'] < esik_deger] 
        
        if cluster_col in df_filtered.columns:
            unique_clusters = sorted(df_filtered[cluster_col].unique())
            
            for cluster_id in unique_clusters:
                cluster_df = df_filtered[df_filtered[cluster_col] == cluster_id]
                
                # Her kÃ¼meden rastgele 50 kiÅŸi al (sample), head(50) deÄŸil!
                # head() yaparsan sadece en tepedekileri alÄ±rsÄ±n, sample() karÄ±ÅŸÄ±k alÄ±r.
                if len(cluster_df) > 50:
                    sample_data = cluster_df[['monetary', 'frequency']].sample(50).values.tolist()
                else:
                    sample_data = cluster_df[['monetary', 'frequency']].values.tolist()
                
                series_data.append({
                    "name": f"Segment {cluster_id}", 
                    "data": sample_data
                })
                
        return series_data

    except Exception as e:
        print(f"HATA: {e}")
        return []
                                    

# ==========================================
# 4. PREDICTION ENGINE (TAHMÄ°N MOTORU) ğŸ§ 
# ==========================================

# Global deÄŸiÅŸkenler (Modelleri bir kere yÃ¼kle, her defasÄ±nda yorma)
kmeans_model = None
scaler_model = None

# Global deÄŸiÅŸkenler
kmeans_model = None
scaler_model = None

def load_models():
    """Uygulama baÅŸlarken Joblib ile eÄŸitilmiÅŸ modelleri yÃ¼kler."""
    global kmeans_model, scaler_model
    
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    # ArkadaÅŸÄ±nÄ±n kaydettiÄŸi dosya yollarÄ±
    model_path = os.path.join(base_dir, 'models', 'kmeans_model.pkl')
    scaler_path = os.path.join(base_dir, 'models', 'scaler.pkl')
    
    try:
        if os.path.exists(model_path) and os.path.exists(scaler_path):
            kmeans_model = joblib.load(model_path)
            scaler_model = joblib.load(scaler_path)
            
            print(f"âœ… Joblib Modelleri YÃ¼klendi!\nğŸ“‚ Model: {model_path}")
        else:
            print("âš ï¸ UYARI: Model dosyalarÄ± bulunamadÄ±. LÃ¼tfen 'scripts/train_model.py' Ã§alÄ±ÅŸtÄ±rÄ±n.")
    except Exception as e:
        print(f"âŒ Model YÃ¼kleme HatasÄ± (Joblib): {e}")

# Uygulama baÅŸlarken Ã§alÄ±ÅŸtÄ±r
load_models()


# ==========================================
# 3. APP ROUTES (YÃ–NLENDÄ°RMELER)
# ==========================================

@app.route('/')
def index():
    """
    Ana Sayfa YÃ¶nlendirmesi.
    TÃ¼m analiz modÃ¼llerini Ã§alÄ±ÅŸtÄ±rÄ±r ve sonuÃ§larÄ± 'index.html' ÅŸablonuna gÃ¶nderir.
    """
    
    # Veri modÃ¼llerinden sonuÃ§larÄ± Ã§ek
    rfm_context = get_rfm_data()
    kmeans_series = get_kmeans_data()
    
    # Veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ kontrolÃ¼
    if rfm_context is None:
        return "<h1>Sistem HatasÄ±</h1><p>Veri dosyalarÄ± okunamadÄ±. LÃ¼tfen sunucu loglarÄ±nÄ± kontrol edin.</p>"

    # Frontend'e veri enjeksiyonu
    return render_template('index.html', 
                           **rfm_context,          # RFM verilerini unpack et
                           scatter_verisi=kmeans_series # K-Means verisini ekle
                           )

# API Endpoint: Tahmin Yap (POST /api/predict)
@app.route('/api/predict', methods=['POST'])
def predict_segment():
    """
    Frontend'den gelen veriyi alÄ±r, Joblib modelleriyle tahmin yapar.
    """
    # Global modelleri kontrol et
    if not kmeans_model or not scaler_model:
        return jsonify({'success': False, 'error': 'Modeller sunucuda yÃ¼klÃ¼ deÄŸil!'}), 500

    try:
        # 1. Veriyi al
        data = request.json
        
        # 2. DeÄŸerleri hazÄ±rla
        recency = float(data.get('recency'))
        frequency = float(data.get('frequency'))
        monetary = float(data.get('monetary'))
        
        # 3. Model formatÄ±na Ã§evir (2 Boyutlu array)
        # Scaler beklediÄŸi iÃ§in Ã¶nce Ã¶lÃ§eklendiriyoruz
        input_data = np.array([[recency, frequency, monetary]])
        input_scaled = scaler_model.transform(input_data)
        
        # 4. Tahmin yap
        cluster_id = kmeans_model.predict(input_scaled)[0]
        
        # 5. CevabÄ± gÃ¶nder
        return jsonify({
            'success': True,
            'cluster': int(cluster_id)
        })

    except Exception as e:
        print(f"Tahmin HatasÄ±: {e}")
        return jsonify({'success': False, 'error': str(e)}), 400
    
if __name__ == '__main__':
    app.run(debug=True)